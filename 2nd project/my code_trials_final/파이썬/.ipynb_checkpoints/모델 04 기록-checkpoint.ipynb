{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f18442",
   "metadata": {},
   "source": [
    "## 특성 및 모델 변경\n",
    "- 그동안 계속 3차원 데이터로 추출하여 CNN 모델에 적용했던 걸 변경, 특성들을 평균화하여 2차원 데이터로 만들고 다른 모델들을 써 보기로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fe303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptual_sharpness(audio_path, sr=16000, n_fft=512, hop_length=256):\n",
    "    # 음원 파일 로드\n",
    "    y= audio_path\n",
    "    sr = sr\n",
    "\n",
    "    # STFT 수행\n",
    "    D = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
    "\n",
    "    # 주파수 대역별로 에너지 계산\n",
    "    energy = np.sum(D, axis=0)\n",
    "\n",
    "    # 고주파수 대역 성분 추출\n",
    "    high_freq_energy = energy[3000:8000]  # 예시로 3000Hz에서 6000Hz 사이의 주파수 대역을 고주파수 대역으로 설정\n",
    "\n",
    "    # Perceptual Sharpness 계산\n",
    "    sharpness = np.sum(np.log1p(high_freq_energy))\n",
    "\n",
    "    return sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    \n",
    "    audio, sr = librosa.load(file_name, sr=16000)\n",
    "    \n",
    "        ##Mel-spectrogram 구현\n",
    "    spectrogram = librosa.stft(audio, n_fft=512, hop_length= 256) \n",
    "    power_spectrogram = spectrogram**2\n",
    "    mel = librosa.feature.melspectrogram(S=power_spectrogram, sr=sr)\n",
    "    mel = librosa.power_to_db(np.abs(mel)**2)\n",
    "    #mfcc 구현\n",
    "    mfccs = librosa.feature.mfcc(S = mel, n_mfcc=20)\n",
    "\n",
    "    stft = np.abs(spectrogram)\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=stft,hop_length=512)\n",
    "    rms = librosa.feature.rms(y=audio)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    spectral_bandwidths = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    zero_crossing_rates = librosa.feature.zero_crossing_rate(y=audio)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr)\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "    ps = perceptual_sharpness(audio)\n",
    "    \n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    mfccs_var = mfccs.mean(axis=1)\n",
    "    \n",
    "    for i in range(len(mfccs_mean)):\n",
    "        locals()[f'mfccs_mean_{i}'] = mfccs_mean[i]\n",
    "        locals()[f'mfccs_var_{i}'] = mfccs_var[i]\n",
    "    chroma_stft_mean = chroma_stft.mean()\n",
    "    chroma_stft_var = chroma_stft.var()\n",
    "    rms_mean = rms.mean()\n",
    "    rms_var = rms.var()\n",
    "    spectral_centroids_mean = spectral_centroids.mean()\n",
    "    spectral_centroids_var = spectral_centroids.var()\n",
    "    spectral_bandwidths_mean = spectral_bandwidths.mean()\n",
    "    spectral_bandwidths_var = spectral_bandwidths.var()\n",
    "    spectral_rolloff_mean = spectral_rolloff.mean()\n",
    "    spectral_rolloff_var = spectral_rolloff.var()\n",
    "    zero_crossing_rates_mean = zero_crossing_rates.mean()\n",
    "    zero_crossing_rates_var = zero_crossing_rates.var()\n",
    "    harmony_mean = chroma_cens.mean()\n",
    "    harmony_var = chroma_cens.var()\n",
    "    tempo_mean = tempo.mean()\n",
    "    tempo_var = tempo.var()\n",
    "    perceptual_sharpness_mean = ps.mean()\n",
    "    perceptual_sharpness_var = ps.var()\n",
    "    \n",
    "    #합치기\n",
    "    features = np.array([])\n",
    "    for j in range(20):\n",
    "        features = np.hstack((features,locals()[f'mfccs_mean_{j}'],locals()[f'mfccs_var_{j}']))\n",
    "    \n",
    "    features = np.hstack((features,chroma_stft_mean,chroma_stft_var,rms_mean,rms_var,spectral_centroids_mean\n",
    "                         ,spectral_centroids_var, spectral_bandwidths_mean, spectral_bandwidths_var,spectral_rolloff_mean\n",
    "                         , spectral_rolloff_var,zero_crossing_rates_mean, zero_crossing_rates_var, harmony_mean, harmony_var\n",
    "                         , tempo_mean,tempo_var,perceptual_sharpness_mean,perceptual_sharpness_var))\n",
    "    features = scale(features)\n",
    "#     features = np.pad(features,(2,2),mode='constant')\n",
    "    \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 리스트 만들기\n",
    "test_df = pd.DataFrame([os.listdir(test_path)[i][:-4] for i in range(len(os.listdir(test_path)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a468c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    train_data = []\n",
    "#     file_list = data['wav_id']\n",
    "    file_list = data[0] #테스트용\n",
    "\n",
    "#     audio_path = train_audio_path\n",
    "    audio_path = test_path #테스트용\n",
    "    for i, file_name in tqdm(enumerate(file_list)):\n",
    "        features = extract_features(os.path.join(audio_path, f'{file_name}.wav'))\n",
    "        train_data.append(features)\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'{i+1}번째 파일 완료')\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d415aa",
   "metadata": {},
   "source": [
    "### 트러블 발생\n",
    "- 약 29000번째 전후 데이터에서 float은 mean을 할 수 없다는 오류가 뜸...왜?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964482fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = train_csv\n",
    "train_data = []\n",
    "file_list = data['wav_id']\n",
    "# file_list = data[0] #테스트용\n",
    "\n",
    "audio_path = train_audio_path\n",
    "# audio_path = test_path #테스트용\n",
    "for i, file_name in tqdm(enumerate(file_list)):\n",
    "\n",
    "    audio, sr = librosa.load(os.path.join(audio_path, f'{file_name}.wav'), sr=16000)\n",
    "        ##Mel-spectrogram 구현\n",
    "    spectrogram = librosa.stft(audio, n_fft=512, hop_length= 256) \n",
    "    power_spectrogram = spectrogram**2\n",
    "    mel = librosa.feature.melspectrogram(S=power_spectrogram, sr=sr)\n",
    "    mel = librosa.power_to_db(np.abs(mel)**2)\n",
    "    #mfcc 구현\n",
    "    mfccs = librosa.feature.mfcc(S = mel, n_mfcc=20)\n",
    "\n",
    "    stft = np.abs(spectrogram)\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=stft,hop_length=512)\n",
    "    rms = librosa.feature.rms(y=audio)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    spectral_bandwidths = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    zero_crossing_rates = librosa.feature.zero_crossing_rate(y=audio)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr)\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "    ps = perceptual_sharpness(audio)\n",
    "    \n",
    "    try:\n",
    "        mfccs_mean = mfccs.mean(axis=1)\n",
    "        mfccs_var = mfccs.mean(axis=1)\n",
    "\n",
    "        for k in range(len(mfccs_mean)):\n",
    "            locals()[f'mfccs_mean_{k}'] = mfccs_mean[k]\n",
    "            locals()[f'mfccs_var_{k}'] = mfccs_var[k]\n",
    "        chroma_stft_mean = chroma_stft.mean()\n",
    "        chroma_stft_var = chroma_stft.var()\n",
    "        rms_mean = rms.mean()\n",
    "        rms_var = rms.var()\n",
    "        spectral_centroids_mean = spectral_centroids.mean()\n",
    "        spectral_centroids_var = spectral_centroids.var()\n",
    "        spectral_bandwidths_mean = spectral_bandwidths.mean()\n",
    "        spectral_bandwidths_var = spectral_bandwidths.var()\n",
    "        spectral_rolloff_mean = spectral_rolloff.mean()\n",
    "        spectral_rolloff_var = spectral_rolloff.var()\n",
    "        zero_crossing_rates_mean = zero_crossing_rates.mean()\n",
    "        zero_crossing_rates_var = zero_crossing_rates.var()\n",
    "        harmony_mean = chroma_cens.mean()\n",
    "        harmony_var = chroma_cens.var()\n",
    "        tempo_mean = tempo.mean()\n",
    "        tempo_var = tempo.var()\n",
    "        perceptual_sharpness_mean = ps.mean()\n",
    "        perceptual_sharpness_var = ps.var()\n",
    "    except:\n",
    "        print(f'{i}번째 파일에서 문제 발생')\n",
    "        continue\n",
    "\n",
    "    #합치기\n",
    "    features = np.array([])\n",
    "    for j in range(20):\n",
    "        features = np.hstack((features,locals()[f'mfccs_mean_{j}'],locals()[f'mfccs_var_{j}']))\n",
    "\n",
    "    features = np.hstack((features,chroma_stft_mean,chroma_stft_var,rms_mean,rms_var,spectral_centroids_mean\n",
    "                         ,spectral_centroids_var, spectral_bandwidths_mean, spectral_bandwidths_var,spectral_rolloff_mean\n",
    "                         , spectral_rolloff_var,zero_crossing_rates_mean, zero_crossing_rates_var, harmony_mean, harmony_var\n",
    "                         , tempo_mean,tempo_var,perceptual_sharpness_mean,perceptual_sharpness_var))\n",
    "#     features = scale(features)\n",
    "#     features = extract_features(os.path.join(audio_path, f'{file_name}.wav')) - 일단  스케일링 없이 뽑고 이상치 확인 후 제거\n",
    "    train_data.append(features)\n",
    "    if i>0 and i%100 == 0:\n",
    "        print(f'{i}번째 파일 완료')\n",
    "        locals()[f'X_{int(i/100)}'] = pd.DataFrame(train_data) #i/는 실수형으로 나오니까 i//를 쓰든지 이렇게 int화하든지\n",
    "        \n",
    "        #아마 또 28980쯤에서 오류 날 테니까 해당 파일 뜯어봐서 문제가 뭔지 발견하고 다시 진행한 다음 28900까지 저장된 X_289 DF랑 합치자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(pd.concat((X_289,train_data))).reshape(-1,58)\n",
    "features.shape\n",
    "\n",
    "\n",
    "#28980번 파일을 제외한 나머지를 features4로 저장\n",
    "\n",
    "#문제의 28980번 파일 확인 후 제거\n",
    "train_csv = train_csv.drop(index=28980)\n",
    "np.save('./features4.npy',features)\n",
    "train_csv.to_csv('e:/Data2/csv/train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the random search\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , train_csv['감정'],random_state=0, stratify = train_csv['감정'], test_size = 0.3)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 15),  # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weight function\n",
    "    'p': [1, 2]  # Power parameter for the Minkowski distance metric\n",
    "}\n",
    "\n",
    "# Create the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform the random search\n",
    "random_search_knn = RandomizedSearchCV(\n",
    "    knn, param_distributions=param_grid, n_iter=10, cv=5, random_state=42\n",
    ")\n",
    "random_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the KNN model with the best parameters on the test set\n",
    "best_knn = random_search_knn.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "test_accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Evaluate the KNN model on the training set\n",
    "y_train_pred_knn = best_knn.predict(X_train)\n",
    "train_accuracy_knn = accuracy_score(y_train, y_train_pred_knn)\n",
    "\n",
    "print(\"Train KNN Accuracy:\", train_accuracy_knn)\n",
    "print(\"Test KNN Accuracy:\", test_accuracy_knn)\n",
    "\n",
    "\n",
    "#결과값 약 38% 나옴\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
