{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ba1fd5",
   "metadata": {},
   "source": [
    "모델의 기본적인 구조는 입력차원을 제외하면 이전과 같은 형태, 추출 특성을 바꿔서 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfcc와 chroma만 추출해 보기로\n",
    "\n",
    "def extract_mfcc_feature(file_name):\n",
    "    \n",
    "    y, sr = librosa.load(file_name, sr=16000)\n",
    "    \n",
    "    #spectrogram 구현\n",
    "    spectrogram = librosa.stft(y, n_fft=512, hop_length= 256) #\n",
    "    #   일반적으로 n_fft는 256, 512, 1024, 2048과 같은 2의 거듭제곱의 값 사용. \n",
    "    #   일반적으로 음성 신호의 경우 20ms에서 40ms 사이의 길이의 윈도우를 사용하는 것이 일반적\n",
    "    #   대략 16000Hz의 샘플링 주파수를 갖는 경우, n_fft는 대략 320(= 16000 * 0.02)과 640(= 44100 * 0.04) 사이가 적절\n",
    "    #   즉 이 경우 512가 가장 적절\n",
    "    #   hop-length는 n_fft의 절반으로 설정하는 것이 일반적\n",
    "\n",
    "    spectrogram = np.abs(spectrogram) #shape=(1025, 150)\n",
    "    \n",
    "    #Mel-spectrogram 구현\n",
    "    power_spectrogram = spectrogram**2\n",
    "    mel = librosa.feature.melspectrogram(S=power_spectrogram, sr=sr)\n",
    "    mel = librosa.power_to_db(mel)\n",
    "    \n",
    "    #mfcc 구현\n",
    "    mfccs = librosa.feature.mfcc(S = mel, n_mfcc=200)\n",
    "    mfccs = pad_sequences(mfccs, maxlen=200, padding='post',dtype='float32')\n",
    "#     mfccs = normalize(mfccs,axis=1)\n",
    "    mfccs = pad_sequences(mfccs.T, maxlen=60, padding='post',dtype='float32')\n",
    "    \n",
    "    #Chroma 구현\n",
    "    stft = np.abs(librosa.stft(y))\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=stft,hop_length=512)\n",
    "    chroma_stft = pad_sequences(chroma_stft, maxlen=200, padding='post',dtype='float32')\n",
    "#     chroma_stft = normalize(chroma_stft,axis=1)\n",
    "    chroma_stft = pad_sequences(chroma_stft.T, maxlen=60, padding='post',dtype='float32')\n",
    "    \n",
    "    #합치기\n",
    "    \n",
    "    features = np.hstack((mfccs,chroma_stft))\n",
    "    features = np.pad(features,((0,0),(2,2)),mode='constant')\n",
    "    features = scale(features, axis=1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c6440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "def second_model(x_train):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(400,64)))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ecca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_info, isTrain=True):\n",
    "    if isTrain:\n",
    "        X = []\n",
    "#         file_list = data_info['wav_id']\n",
    "        file_list = pd.DataFrame(os.listdir(test_path)).iloc[:,0] #테스트용\n",
    "\n",
    "#         audio_path = (train_audio_path) \n",
    "        audio_path = test_path #테스트용\n",
    "#         for file_name, emotion in tqdm(zip(file_list, emotion_list)):\n",
    "        for file_name in tqdm(file_list):\n",
    "        \n",
    "#             features = extract_mfcc_feature(os.path.join(audio_path, f'{file_name}.wav'))\n",
    "            features = extract_mfcc_feature(os.path.join(audio_path, f'{file_name}')) #테스트용\n",
    "            \n",
    "            X.append(features)\n",
    "#         train_data= np.array(X).reshape(-1,400,64) \n",
    "            \n",
    "        return X #, np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#스케일링 - 데이터를 평균 0, 표준편차 1로 스케일을 축소\n",
    "\n",
    "y = train_csv.iloc[:,-7:]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_train)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "model = second_model(X_train)\n",
    "history=model.fit(X_train, y_train, batch_size=40, epochs=50, validation_data=(X_test, y_test), callbacks=[rlrp,mcp])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "#결과 tes_acc는 약 42%가 최대"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
