{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a57c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydub #오디오 파일을 다루는 라이브러리 : 변환 조작 재생 분석 등\n",
    "# import gTTS # 텍스트를 음성으로 변환하는 라이브러리. 나는 당장 쓸 일 없을 듯?\n",
    "\n",
    "from tqdm import tqdm\n",
    "import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import winsound as sd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import sys\n",
    "import logging\n",
    "import unicodedata\n",
    "from shutil import copyfile\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "# import json, pandas as pd # ?? 이러면 어떻게 되는 거지?\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "# import pydub #오디오 파일을 다루는 라이브러리 : 변환 조작 재생 분석 등\n",
    "# import gTTS # 텍스트를 음성으로 변환하는 라이브러리. 나는 당장 쓸 일 없을 듯?\n",
    "# import speech_recognition as sr #음성인식 라이브러리 - 텍스트로 변환\n",
    "import pyaudio\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, scale\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import keras\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11d4d1",
   "metadata": {},
   "source": [
    "## 데이터 구조\n",
    "- AI-Hub의 감정이 태깅된 자유대화(성인)\n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=data&dataSetSn=71631\n",
    "- 음성파일과 그 음성파일에 대한 메타데이터를 기록한 csv 파일이 한 쌍으로 되어 있음\n",
    "- csv의 음성 관련 정보는 파일 전체에 대한 것이 아니라 파일의 부분 부분에 대해 기록되어 있음\n",
    "    - 시작시간 : 00분 00초, 종료시간 : 00분 00초, 텍스트 : xxxxx, 감정 : xxxx 이런 식으로\n",
    "    - - 감정의 경우 기쁨, 슬픔, 분노, 공포, 놀라움, 중립, 사랑스러움의 7가지 분류\n",
    "- 따라서 csv에 기록된 데이터에 따라 시작시간부터 (종료시간 - 시작시간) 사이의 기간까지의 음성으로부터 그 특성을 추출하고\n",
    "- csv에 기재된 감정을 해당 특성의 레이블로 삼기로 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'e:/sampleForTest/raw/'\n",
    "json_path  = 'e:/sampleForTest/tag/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file,n):\n",
    "    result=np.array([])\n",
    "    with open(json_path+name_list[n]+'.json',encoding='utf-8') as f: #오디오 파일과 이름이 같은 json 파일 열기\n",
    "        js = json.loads(f.read())\n",
    "    for i in range(len(js['Conversation'])):\n",
    "        stt= float(js['Conversation'][i]['StartTime'].replace(',',''))\n",
    "        edt= float(js['Conversation'][i]['EndTime'].replace(',',''))  \n",
    "        data, sr = librosa.load(file,sr=None,duration=(edt-stt), offset=stt,res_type='kaiser_best')\n",
    "        res1 = np.array([])\n",
    "        if len(data)==0:\n",
    "    # without augmentation\n",
    "            print(f'{n}file {i}data is empty')\n",
    "            data_error.append([n,i])\n",
    "            continue\n",
    "        else:          \n",
    "            res1 = extract_features(data, sr,n,stt,edt)\n",
    "#         result = np.hstack((result,np.array(res1)))\n",
    "#         print(res1)\n",
    "            if len(res1)!=14:\n",
    "                print(f\"{n}file {i}'s length of feature is {len(result)}\")\n",
    "                feature_error.append([n,i])\n",
    "            else:\n",
    "                result = np.append(result,res1) \n",
    "                result = result.reshape(-1,14)  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb60c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, sample_rate,n,stt,edt):\n",
    "    # 윈도우 크기와 스트라이드 정의                         \n",
    "    window_size = int(sample_rate * 0.025)  \n",
    "    hop_length = int(sample_rate * 0.0125)   \n",
    "\n",
    "\n",
    "    # 시작 프레임과 종료 프레임 계산\n",
    "    start_frame = int(stt * sample_rate / hop_length)\n",
    "    end_frame = int(edt * sample_rate / hop_length)                         \n",
    "\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate,n_fft=window_size, hop_length=hop_length).T, axis=0)\n",
    "    # 해당 구간에 대한 MFCC 추출\n",
    "    mfcc_partial = mfcc[start_frame:end_frame]\n",
    "    result = np.hstack((result, mfcc_partial)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate,n_fft=window_size, hop_length=hop_length).T, axis=0)\n",
    "    # 해당 구간에 대한 Mel Spectrogram 추출\n",
    "    mel_partial = mel[start_frame:end_frame]\n",
    "    result = np.hstack((result, mel_partial)) # stacking horizontally\n",
    "            \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 파트 중 가장 시간이 긴 파트와 해당 찾기\n",
    "#이걸 추출해서 이를 기준으로 다 패딩을 줘버릴 거다.\n",
    "\n",
    "audio_path = 'E:/Data/Training/X/'\n",
    "json_path  = 'E:/Data/Training/y/'\n",
    "\n",
    "#valid 데이터\n",
    "# audio_path = 'E:/Data/Validation/X/'\n",
    "# json_path  = 'E:/Data/Validation/y/'\n",
    "\n",
    "max_time_index = ''\n",
    "max_time=0\n",
    "name_list  = [i[:-5] for i in  os.listdir(json_path)]\n",
    "# name_list\n",
    "for i in range(len(os.listdir(audio_path))):\n",
    "    with open(json_path+name_list[i]+'.json',encoding='utf-8') as f: #오디오 파일과 이름이 같은 json 파일 열기\n",
    "        js = json.loads(f.read())        \n",
    "        for j in range(len(js['Conversation'])):\n",
    "            stt= float(js['Conversation'][j]['StartTime'].replace(',',''))\n",
    "            edt= float(js['Conversation'][j]['EndTime'].replace(',',''))  \n",
    "#             y, sr = librosa.load(audio_path+name_list[i]+'.wav',sr=16000,duration=(edt-stt), offset=stt,res_type='kaiser_fast')\n",
    "            if edt-stt>max_time:\n",
    "                max_time=edt-stt\n",
    "                max_time_index = f'{i}_{j}'\n",
    "print(max_time)\n",
    "print(max_time_index)\n",
    "#추출 결과 : 7987번째 파일(2_5632G1A3_5628G1A3_T1_2D09T0402C000465_025188.wav)의 340번째 데이터 길이가 가장 긴 것으로.\n",
    "#이제 이 값의 mfcc를 추출해야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#최장 mfcc 추출\n",
    "\n",
    "audio_path = 'E:/Data/Training/X/'\n",
    "json_path  = 'E:/Data/Training/y/'\n",
    "with open(json_path+'2_5632G1A3_5628G1A3_T1_2D09T0402C000465_025188'+'.json',encoding='utf-8') as f: #오디오 파일과 이름이 같은 json 파일 열기\n",
    "    js = json.loads(f.read())        \n",
    "    stt= float(js['Conversation'][340]['StartTime'].replace(',',''))\n",
    "    edt= float(js['Conversation'][340]['EndTime'].replace(',',''))\n",
    "    y, sr = librosa.load(audio_path+'2_5632G1A3_5628G1A3_T1_2D09T0402C000465_025188'+'.wav',sr=16000,duration=(edt-stt), offset=stt,res_type='kaiser_fast')\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=13).T\n",
    "mfcc.shape\n",
    "\n",
    "#1629...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91405b56",
   "metadata": {},
   "source": [
    "### 트러블 발생(1)\n",
    "\n",
    "- 1629 길이로 패딩해서 특성 추출하려고 했더니 하다가 메모리 부족으로 오류 남\n",
    "- 특성의 길이를 줄여보기로(코드는 패딩 길이 줄인 것 빼고 아래와 동일했음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda71069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수 정의\n",
    "\n",
    "def get_features(path):\n",
    "\n",
    "    all_features = []\n",
    "\n",
    "    for i in range(len(os.listdir(path+'X/'))):\n",
    "        with open(path+'y/'+name_list[i]+'.json',encoding='utf-8') as f: #오디오 파일과 이름이 같은 json 파일 열기\n",
    "            js = json.loads(f.read())        \n",
    "            for j in range(len(js['Conversation'])):\n",
    "                stt= float(js['Conversation'][j]['StartTime'].replace(',',''))\n",
    "                edt= float(js['Conversation'][j]['EndTime'].replace(',',''))  \n",
    "                y, sr = librosa.load(path+'X/'+name_list[i]+'.wav',sr=16000,duration=(edt-stt), offset=stt,res_type='kaiser_fast')\n",
    "\n",
    "\n",
    "                    # 특성들 추출\n",
    "                mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr,n_mfcc=13),axis=1)\n",
    "                spec_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr),axis=1)\n",
    "                spec_cont = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr),axis=1)\n",
    "                spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr),axis=1)\n",
    "                spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr),axis=1)\n",
    "                spec_flat = np.mean(librosa.feature.spectral_flatness(y=y),axis=1)\n",
    "                inharmonicity = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr),axis=1)\n",
    "                harmonic, percussive = librosa.effects.hpss(y)\n",
    "                harmonic_energy = np.mean(librosa.feature.rms(y=harmonic),axis=1)\n",
    "                noise_energy = np.mean(librosa.feature.rms(y=percussive),axis=1)\n",
    "                # chroma 차원 확장하여 concat 가능한 형태로 변환\n",
    "                C = np.abs(librosa.cqt(y, sr=sr, bins_per_octave=12, n_bins=7*12))\n",
    "                # 크로마 CQT 스펙트럼을 크로마 그램으로 변환\n",
    "                chroma = np.mean(librosa.feature.chroma_cqt( C=C,n_chroma=12),axis=1)\n",
    "                features = np.concatenate([mfcc, spec_rolloff, spec_cont, spec_cent,\n",
    "                                               spec_bw, spec_flat, inharmonicity,\n",
    "                                               harmonic_energy, noise_energy,  chroma], axis=0)\n",
    "                all_features.append(features)\n",
    "\n",
    "\n",
    "    ## 전체 feature 계산해서 파일로 저장            \n",
    "    all_features = np.array(all_features)\n",
    "    all_features.T\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features_normalized = scaler.fit_transform(all_features)\n",
    "    final_features = np.expand_dims(features_normalized, axis=1)\n",
    "\n",
    "    #파일로 저장\n",
    "    np.save(path+'final_features',final_features)\n",
    "\n",
    "    all_label=[]\n",
    "    for i in range(len(os.listdir(path+'X/'))):\n",
    "        with open(path+'y/'+name_list[i]+'.json',encoding='utf-8') as f:\n",
    "            js = json.loads(f.read())\n",
    "            for j in range(len(js['Conversation'])):\n",
    "                all_label.append(js['Conversation'][j]['VerifyEmotionTarget'])\n",
    "    all_label_df = pd.get_dummies(all_label,dtype=int)\n",
    "    all_label_df.to_csv(path+'all_label_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1841793",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path, vali_path = 'E:/Data/Training/','E:/Data/Validation/'\n",
    "get_features(train_path)\n",
    "get_features(vali_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e76687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실전용\n",
    "# 추출 대상 : 오류 리스트(데이터, 특성 개수, \n",
    "\n",
    "#트레인 데이터\n",
    "audio_path = 'E:/Data/Training/X/'\n",
    "json_path  = 'E:/Data/Training/y/'\n",
    "\n",
    "#valid 데이터\n",
    "# audio_path = 'E:/Data/Validation/X/'\n",
    "# json_path  = 'E:/Data/Validation/y/'\n",
    "\n",
    "\n",
    "a_cnt = 0\n",
    "a_sav_cnt = 0\n",
    "b_cnt = 0\n",
    "b_sav_cnt = 0\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "name_list  = [i[:-5] for i in  os.listdir(json_path)]\n",
    "\n",
    "data_error =[]\n",
    "\n",
    "for i in range(len(os.listdir(audio_path))):\n",
    "    a.append(get_features(audio_path+name_list[i]+'.wav',i))\n",
    "    a_cnt+=1\n",
    "    if a_cnt == 100:\n",
    "        df_a = pd.DataFrame(a[0])\n",
    "        column_list = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14']\n",
    "        df_a.columns = column_list\n",
    "        for j in range(1,len(a)):\n",
    "            if len(a[j])>0:\n",
    "                df_a_new = pd.DataFrame(a[j])\n",
    "                df_a_new.columns = column_list\n",
    "                df_a  =pd.concat([df_a,df_a_new])\n",
    "            else:\n",
    "                print(f'{j}번 항목의 값이 없습니다')\n",
    "        df_a.to_csv(f'./train_list/a000{a_sav_cnt}.csv')\n",
    "#         df_a.to_csv(f'./val_list/a000{a_sav_cnt}.csv')\n",
    "        a_cnt = 0\n",
    "        a_sav_cnt += 1\n",
    "        a=[]\n",
    "        \n",
    "    with open(json_path+name_list[i]+'.json',encoding='utf-8') as f:\n",
    "        js = json.loads(f.read())\n",
    "    for j in range(len(js['Conversation'])):\n",
    "        if [i,j] in data_error:\n",
    "            print(f'{i}파일 {j} 번째 오디오 데이터에 오류가 있는 항목')\n",
    "        else:\n",
    "            if [i,j] in feature_error :\n",
    "                print(f'{i}파일 {j} 번째 특성 데이터에 오류가 있는 항목')\n",
    "            else:\n",
    "                b.append(js['Conversation'][j]['VerifyEmotionTarget'])\n",
    "    b_cnt += 1\n",
    "    if b_cnt == 100:\n",
    "        #train 데이터\n",
    "        file_b = f'./train_list/b000{b_sav_cnt}.txt'\n",
    "        #valid 데이터\n",
    "#         file_b = f'./val_list/b000{b_sav_cnt}.txt'\n",
    "        with open(file_b, 'w+') as file:\n",
    "            file.write('\\n'.join(b))   \n",
    "        b_cnt =0\n",
    "        b_sav_cnt+=1\n",
    "        b=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train DF로 만들기\n",
    "df_a = pd.read_csv('./train_list/a0000.csv')\n",
    "for i in range(1,99): #x에는 저장한 csv, txt 파일의 마지막 번호+1 집어넣자\n",
    "    df_a_new = pd.read_csv(f'./train_list/a000{i}.csv')\n",
    "    df_a  =pd.concat([df_a,df_a_new])\n",
    "df_a = df_a.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 라벨 데이터 DF로 만들기\n",
    "b=[]\n",
    "for i in range(99):\n",
    "\n",
    "    with open(f'./train_list/b000{i}.txt', 'r',encoding='euc-kr') as file:\n",
    "        for j in file:\n",
    "            b.append(j.strip())\n",
    "df_b=pd.get_dummies(b,dtype=int)\n",
    "with open(f'./train_list/final_ytrain.txt', 'w+') as file:\n",
    "    file.write('\\n'.join(b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8464abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vali DF로 만들기\n",
    "df_a_val = pd.read_csv('./val_list/a0005.csv')\n",
    "for i in range(6,17): #x에는 저장한 csv, txt 파일의 마지막 번호+1 집어넣자\n",
    "    df_a_new = pd.read_csv(f'./data/val_list/a000{i}.csv')\n",
    "    df_a_val  =pd.concat([df_a_val,df_a_new])\n",
    "df_a_val = df_a_val.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86756c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vali 라벨 데이터 DF로 만들기\n",
    "b=[]\n",
    "for i in range(5,17):\n",
    "    with open(f'./val_list/b000{i}.txt', 'r',encoding='euc-kr') as file:\n",
    "        for j in file:\n",
    "            b.append(j.strip())\n",
    "df_b_val=pd.get_dummies(b,dtype=int)\n",
    "with open(f'./val_list/final_ytest.txt', 'w+') as file:\n",
    "    file.write('\\n'.join(b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fa4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에 추출 끝난 데이터들 파일로 저장한 거 불러오기(위의 작업 반복할 필요 없다)\n",
    "df_a = pd.read_csv('./train_list/final_Xtrain.csv')\n",
    "df_a_val = pd.read_csv('./val_list/final_Xval.csv')\n",
    "df_b = pd.read_csv('./train_list/final_ytrain.csv')\n",
    "df_b_val = pd.read_csv('./val_list/final_yval.csv')\n",
    "\n",
    "df_a = df_a.iloc[:,1:]\n",
    "df_a_val = df_a_val.iloc[:,1:]\n",
    "df_b = df_b.iloc[:,1:]\n",
    "df_b_val = df_b_val.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "\n",
    "X_train_raw = np.array(df_a)\n",
    "# X_train_raw = scaler.fit_transform(X_train_raw)\n",
    "X_train_raw = X_train_raw.reshape(X_train_raw.shape[0],1,X_train_raw.shape[1])\n",
    "X_test_raw = np.array(df_a_val)\n",
    "# X_test_raw = scaler.transform(X_test_raw)\n",
    "X_test_raw = X_test_raw.reshape(X_test_raw.shape[0],1,X_test_raw.shape[1])\n",
    "y_train_raw = np.array(df_b)\n",
    "y_test_raw = np.array(df_b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "def first_model(x_train):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(58,1)))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495881ab",
   "metadata": {},
   "source": [
    "#### 이 모델의 실행 결과 약 50% 정도의 accuracy가 나왔음.\n",
    "- 들인 시간(약 10일 정도)에 비해 만족스럽지 못한 성능\n",
    "- accuracy를 올리기 위해서는 기반 데이터의 추가 확보, 추출할 특성의 변경, 모델의 설계 변경 등이 있음 \n",
    "- 이 특성 추출에 사용한 기반 데이터는 용량 자체가 큰 데다 이중 for문을 필연적으로 돌려야 하는 문제가 있어 추출 특성을 변경하기에는 특성 추출 시간이 너무 오래 걸려 기반 데이터를 변경하기로 함.\n",
    "- 본 모델에서 사용했던 데이터들 삭제하면서 파일로 내보냈던 특성, 모델도 함께 삭제함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f1243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
