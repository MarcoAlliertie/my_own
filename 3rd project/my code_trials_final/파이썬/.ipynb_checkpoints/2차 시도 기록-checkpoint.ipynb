{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f402299d",
   "metadata": {},
   "source": [
    "#### 데이터 구조\n",
    "- AI-Hub의 감정 분류를 위한 대화 음성 데이터셋\n",
    "    - https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=263\n",
    "- 4차년도, 5차년도, 5차년도 2차라는 세 개의 데이터로 구성되어 있음\n",
    "- 각 년도별로 wav 파일들과 wav 파일에 대한 정보를 담은 csv 파일 하나로 구성되어 있음\n",
    "- csv 파일에는 wav파일들의 이름을 wav_id라는 컬럼에 기재하고 그에 대한 정보를 기록함\n",
    "    - 감정 정보의 경우 라벨링을 담당한 다섯 사람이 하나의 wav파일에 들어있는 음성을 듣고 각각 7가지 감정(기쁨, 슬픔, 분노, 공포, 혐오, 중립, 놀라움) 중 하나로 판단하고 그 다섯 사람의 판단을 전부 기재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26b03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#경고 및 완료확인용 beep 함수\n",
    "def beepError():\n",
    "    fr = 1000    # range : 37 ~ 32767\n",
    "    du = 2000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "def beepSuccess():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1625f",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d45e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfb9793",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'e:/Data2/4th.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m csv_4th \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me:/Data2/4th.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCP949\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m csv_5th \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me:/Data2/5th.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCP949\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m csv_5th2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me:/Data2/5th2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCP949\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'e:/Data2/4th.csv'"
     ]
    }
   ],
   "source": [
    "csv_4th = pd.read_csv('e:/Data2/4차년도.csv',encoding='CP949')\n",
    "csv_5th = pd.read_csv('e:/Data2/5th.csv',encoding='CP949')\n",
    "csv_5th2 = pd.read_csv('e:/Data2/5th2.csv',encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9046ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_labeling(data):\n",
    "    data.rename(columns = {'4번감정세기':'4번 감정세기'},inplace=True) # 다른 컬럼과 띄어쓰기 통일\n",
    "\n",
    "    #감정 레이블 만드는 방법\n",
    "    #데이터 설명에 보면 5인이 각각 라벨링한 것으로 되어 있으므로 1번 감정~5번 감정의 다수결로 감정을 결정\n",
    "    data['감정'] = ''\n",
    "    for i in range(len(data)):\n",
    "        templist = [data.iloc[i]['1번 감정'],data.iloc[i]['2번 감정'],data.iloc[i]['3번 감정'],data.iloc[i]['4번 감정'],data.iloc[i]['5번 감정']]\n",
    "        data.iloc[i,-1] = max(templist,key= templist.count)\n",
    "    print('분노',list(data['감정']).count('Angry'),end=' ')\n",
    "    print('슬픔',list(data['감정']).count('Sadness'),end=' ')\n",
    "    print('중립',list(data['감정']).count('Neutral'),end=' ')\n",
    "    print('혐오',list(data['감정']).count('Disgust'),end=' ')\n",
    "    print('놀람',list(data['감정']).count('Surprise'),end=' ')\n",
    "    print('공포',list(data['감정']).count('Fear'),end=' ')\n",
    "    print('행복',list(data['감정']).count('Happiness'),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb27c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_labeling(csv_4th)\n",
    "emo_labeling(csv_5th)\n",
    "emo_labeling(csv_5th2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f40bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른 csv파일과 감정명 통일(두문자를 대문자로)\n",
    "\n",
    "csv_5th2=csv_5th2.replace({'감정':'angry'}, 'Angry')\n",
    "csv_5th2=csv_5th2.replace({'감정':'sadness'}, 'Sadness')\n",
    "csv_5th2=csv_5th2.replace({'감정':'neutral'}, 'Neutral')\n",
    "csv_5th2=csv_5th2.replace({'감정':'disgust'}, 'Disgust')\n",
    "csv_5th2=csv_5th2.replace({'감정':'surprise'}, 'Surprise')\n",
    "csv_5th2=csv_5th2.replace({'감정':'fear'}, 'Fear')\n",
    "csv_5th2=csv_5th2.replace({'감정':'happiness'}, 'Happiness')\n",
    "\n",
    "csv_5th2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 정보만 담은 새로운 DF 만들기\n",
    "def csv_df_ax1(data):\n",
    "    result = pd.concat((data['wav_id'],data['발화문'],data['감정']),axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_4th_get =csv_df_ax1(csv_4th)\n",
    "csv_5th_get = csv_df_ax1(csv_5th)\n",
    "csv_5th2_get = csv_df_ax1(csv_5th2)\n",
    "\n",
    "csv_fin = pd.concat((csv_4th_get,csv_5th_get,csv_5th2_get))\n",
    "csv_fin.to_csv('e:/Data2/fin_csv.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ca98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#감정에 따른 DF로 나누기\n",
    "\n",
    "emotion_list = ['Angry','Sadness','Neutral','Disgust','Surprise','Fear','Happiness']\n",
    "\n",
    "\n",
    "for i in emotion_list:\n",
    "    locals()[f'csv_{i}'] =csv_forwork[csv_forwork['감정'] == i]\n",
    "    locals()[f'csv_{i}'].reset_index(drop=True,inplace=True)\n",
    "print(len(csv_Neutral))\n",
    "print(len(csv_Angry))\n",
    "print(len(csv_Disgust)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#감정 DF 다시 train,valid set으로 분리 후 합치기\n",
    "\n",
    "# emotion_list = ['Angry','Sadness','Neutral','Disgust','Surprise','Fear','Happiness']\n",
    "\n",
    "\n",
    "for i in emotion_list:\n",
    "    locals()[f'csv_{i}_train'] =locals()[f'csv_{i}'].iloc[:len(locals()[f'csv_{i}'])//3*2,:]\n",
    "    locals()[f'csv_{i}_train'].reset_index(drop=True,inplace=True)\n",
    "    locals()[f'csv_{i}_valid'] =locals()[f'csv_{i}'].iloc[len(locals()[f'csv_{i}_train']):,:]\n",
    "    locals()[f'csv_{i}_valid'].reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_csv = pd.concat((csv_Angry_train,csv_Sadness_train,csv_Neutral_train,csv_Disgust_train,csv_Surprise_train,\n",
    "                       csv_Fear_train,csv_Happiness_train))\n",
    "train_csv.reset_index(drop=True,inplace=True)\n",
    "\n",
    "valid_csv = pd.concat((csv_Angry_valid,csv_Sadness_valid,csv_Neutral_valid,csv_Disgust_valid,csv_Surprise_valid,\n",
    "                       csv_Fear_valid,csv_Happiness_valid))\n",
    "valid_csv.reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_csv.to_csv('e:/Data2/train_csv.csv',index = False)\n",
    "valid_csv.to_csv('e:/Data2/valid_csv.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3ac9c",
   "metadata": {},
   "source": [
    "### 트러블 발생 (2)\n",
    "- 파일 개수와 csv 정보의 수는 일치하는데 csv에는 기재되어 있지만 실존하지 않는 파일 발견\n",
    "- 확인 결과 csv상의 이름과 실제 파일명이 다른 16개의 파일 발견\n",
    "- csv 기록에 없는 파일을 직접 재생하여 듣고 그 내용이 csv 기록의 '발화문'과 일치하는 row의 'wav_id' 항목으로 파일명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fdf98c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 오디오 파일도 train, valid 이동\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwav_id\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m#valid df에 있는 파일명(.wav 제외)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(audio_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.wav\u001b[39m\u001b[38;5;124m'\u001b[39m))): \u001b[38;5;66;03m#전체 파일의 개수만큼의 회수\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me:/Data2/audio/\u001b[39m\u001b[38;5;124m'\u001b[39m)[i][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m a: \u001b[38;5;66;03m# a 리스트에 있는 것과 일치하는 파일명이 나온다면\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "a = list(valid_csv['wav_id']) #valid df에 있는 파일명(.wav 제외)\n",
    "for i in range(len(glob.glob(audio_path+'*.wav'))): #전체 파일의 개수만큼의 회수\n",
    "    try:\n",
    "        if os.listdir('e:/Data2/audio/')[0][:-4] in a: # a 리스트에 있는 것과 일치하는 파일명이 나온다면\n",
    "            #파일이 이동하면서 사전 설정된 반복회수에 비해 파일 수가 줄어드므로 그냥 0번에서 다 분류해버리게 설정\n",
    "            shutil.move(f\"e:/Data2/audio/{os.listdir('e:/Data2/audio/')[0]}\", f\"e:/Data2/valid/{os.listdir('e:/Data2/audio/')[0]}\")\n",
    "            print('valid성공',end=' ')\n",
    "        else:\n",
    "            shutil.move(f\"e:/Data2/audio/{os.listdir('e:/Data2/audio/')[0]}\", f\"e:/Data2/train/{os.listdir('e:/Data2/audio/')[0]}\")\n",
    "            print('train성공',end=' ') #일치하지 않는 파일은 train 폴더에\n",
    "    except:\n",
    "        beepError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83034ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('e:/Data2/csv/train.csv', encoding= 'utf-8')\n",
    "valid_csv = pd.read_csv('e:/Data2/csv/valid.csv',encoding='utf-8')\n",
    "csv_path = 'E:/Data2/csv/'\n",
    "# vector_path = 'E:/Data2/vector/' #당장 안 쓰는 폴더\n",
    "train_audio_path = 'E:/Data2/train/'\n",
    "valid_audio_path = 'E:/Data2/valid/'\n",
    "test_path = 'E:/Data2/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fab91",
   "metadata": {},
   "source": [
    "### 음성 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16eea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    \n",
    "    \n",
    "    name_list = data['wav_id'] \n",
    "    name_list = ['5fbe364744697678c497c07f','5fbe361844697678c497c07e'] #테스트용\n",
    "    all_features=[]\n",
    "    timestep = 40\n",
    "\n",
    "    try:\n",
    "        for i in range(len(name_list)):\n",
    "            y, sr = librosa.load(train_audio_path+name_list[i]+'.wav',sr=16000,res_type='kaiser_fast')\n",
    "        #     y, sr = librosa.load('e:/Data2/test/'+name_list[i]+'.wav',sr=16000,res_type='kaiser_fast') #테스트용\n",
    "\n",
    "            # 특성들 추출\n",
    "            #(특성, 시간) 형태\n",
    "            #시간은 같을 테니까 뒤집어 주고 패딩하기\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=13)\n",
    "            spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "            spec_cont = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            spec_flat = librosa.feature.spectral_flatness(y=y)\n",
    "            inharmonicity = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            harmonic, percussive = librosa.effects.hpss(y)\n",
    "            harmonic_energy = librosa.feature.rms(y=harmonic)\n",
    "            noise_energy = librosa.feature.rms(y=percussive)\n",
    "            # chroma 차원 확장하여 concat 가능한 형태로 변환\n",
    "            C = np.abs(librosa.cqt(y, sr=sr, bins_per_octave=12, n_bins=7*12))\n",
    "            # 크로마 CQT 스펙트럼을 크로마 그램으로 변환\n",
    "            chroma = librosa.feature.chroma_cqt( C=C,n_chroma=12)\n",
    "\n",
    "            mfcc = np.vstack((mfcc,spec_rolloff))\n",
    "            mfcc = np.vstack((mfcc,spec_cont))\n",
    "            mfcc = np.vstack((mfcc,spec_cent))\n",
    "            mfcc = np.vstack((mfcc,spec_bw))\n",
    "            mfcc = np.vstack((mfcc,spec_flat))\n",
    "            mfcc = np.vstack((mfcc,inharmonicity))\n",
    "            mfcc = np.vstack((mfcc,harmonic_energy))\n",
    "            mfcc = np.vstack((mfcc,noise_energy))\n",
    "            mfcc = np.vstack((mfcc,chroma))\n",
    "            mfcc = pad_sequences(mfcc, maxlen=timestep, padding='post',dtype='float32')\n",
    "\n",
    "            mfcc = mfcc.T\n",
    "\n",
    "\n",
    "            mfcc = pad_sequences(mfcc, maxlen=13, padding='post',dtype='float32')\n",
    "\n",
    "            mfcc = np.pad(mfcc, ((0,0),(2,2)), 'constant', constant_values=0)\n",
    "            all_features.append(mfcc)\n",
    "            if i>0 and i%100==0:\n",
    "                print(i,'번째 파일 완료')\n",
    "\n",
    "        all_features = np.array(all_features).reshape(-1,40,17) #테스트용\n",
    "        beepSuccess()\n",
    "    except:\n",
    "        beepError()\n",
    "\n",
    "    return all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33033ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_features(train_csv)\n",
    "np.save('./features',features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= pd.get_dummies(valid_csv['감정'],dtype=int)\n",
    "valid_csv = pd.concat((valid_csv, y),axis =1)\n",
    "y= pd.get_dummies(train_csv['감정'],dtype=int)\n",
    "train_csv = pd.concat((train_csv, y),axis =1)\n",
    "valid_csv.reset_index(drop=True,inplace=True)\n",
    "train_csv.reset_index(drop=True,inplace=True)\n",
    "train_csv.to_csv('e:/Data2/train_csv.csv',index = False)\n",
    "valid_csv.to_csv('e:/Data2/valid_csv.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "def first_model(x_train):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(58,1)))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707999ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#스케일링 - 데이터를 평균 0, 표준편차 1로 스케일을 축소\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_data)\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,y, random_state=0,  test_size = 0.3)\n",
    "\n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "model = first_model(X_train)\n",
    "history=model.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_test, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Pre-trained Model: \", i)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "#결과 accuracy도 test accuracy도 약 45% 전후로 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317e3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
