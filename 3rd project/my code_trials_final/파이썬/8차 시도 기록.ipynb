{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b4aefb",
   "metadata": {},
   "source": [
    "## 목표\n",
    "\n",
    "- 음성 데이터에 변형을 가하고 KFold를 이용해 다양한 학습을 하게 하여 성능을 높인다\n",
    "- CNN 모델과 Kobert-Transformers로 각각 특징을 추출하여 소프트보팅 앙상블 모델을 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebce3ce",
   "metadata": {},
   "source": [
    "### 순서\n",
    "- 1. 필요 모듈들 설치 및 임포트\n",
    "- 2. 기본 데이터 불러오기\n",
    "- 3. 필요한 함수들 설정(모델 포함)\n",
    "- 4. 모델 매개변수 설정\n",
    "- 5. 모델학습\n",
    "- 6. 평가\n",
    "- 7. 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549121be",
   "metadata": {},
   "source": [
    "#### 1. 필요 모듈들 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a14531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# import librosa.display\n",
    "# import IPython.display as ipd\n",
    "# from IPython.display import Audio\n",
    "\n",
    "# from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pydub #오디오 파일을 다루는 라이브러리 : 변환 조작 재생 분석 등\n",
    "# import gTTS # 텍스트를 음성으로 변환하는 라이브러리. 나는 당장 쓸 일 없을 듯?\n",
    "\n",
    "from tqdm import tqdm\n",
    "# import np_utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import nlpaug.augmenter.audio as naa\n",
    "# import wave\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "# import shutil\n",
    "# import sys\n",
    "# import logging\n",
    "# import unicodedata\n",
    "# from shutil import copyfile\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"always\")\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder,  MinMaxScaler, RobustScaler\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.svm import SVC \n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import joblib\n",
    "# from joblib import dump, load\n",
    "# from xgboost import XGBClassifier \n",
    "\n",
    "# import keras\n",
    "# from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping, Callback\n",
    "# from keras.models import Sequential\n",
    "# from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, concatenate\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from kobert_transformers import get_kobert_model, get_distilkobert_model, get_tokenizer\n",
    "\n",
    "# np.bool = np.bool_\n",
    "\n",
    "# import mxnet\n",
    "# import gluonnlp as nlp\n",
    "\n",
    "# from transformers import AdamW\n",
    "# from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "# from transformers import BertModel\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift # 음성 데이터 증강용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3139465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kobert-transformers in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from kobert-transformers) (2.2.2)\n",
      "Requirement already satisfied: transformers<5,>=3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from kobert-transformers) (4.40.2)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from kobert-transformers) (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.1.0->kobert-transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.1.0->kobert-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.1.0->kobert-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.1.0->kobert-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.1.0->kobert-transformers) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.1.0->kobert-transformers) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from transformers<5,>=3->kobert-transformers) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers<5,>=3->kobert-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.1.0->kobert-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers<5,>=3->kobert-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers<5,>=3->kobert-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers<5,>=3->kobert-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->transformers<5,>=3->kobert-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from sympy->torch>=1.1.0->kobert-transformers) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=6>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=7>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=8>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audiomentations\n",
      "  Downloading audiomentations-0.35.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from audiomentations) (1.26.4)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from audiomentations) (0.10.2)\n",
      "Requirement already satisfied: scipy<2,>=1.4.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from audiomentations) (1.13.0)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from audiomentations) (0.3.7)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2024.2.2)\n",
      "Downloading audiomentations-0.35.0-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.3 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 30.7/82.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 82.3/82.3 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: audiomentations\n",
      "Successfully installed audiomentations-0.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=6>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=7>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=8>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "!pip install kobert-transformers\n",
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc94c37",
   "metadata": {},
   "source": [
    "#### 2. 기본 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f382e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('e:/Data2/csv/train.csv')\n",
    "test_csv = pd.read_csv('e:/Data2/csv/test.csv')\n",
    "exam_list = ['5fbe364744697678c497c07f','5fbe361844697678c497c07e']\n",
    "\n",
    "train_audio_path = 'e:/Data2/train/'\n",
    "test_audio_path = 'e:/Data2/valid/'\n",
    "exam_audio_path = 'e:/Data2/exam/'\n",
    "\n",
    "# X = np.load('./features/features5.npy')\n",
    "y = train_csv.iloc[:,-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28146d60",
   "metadata": {},
   "source": [
    "#### 3. 필요한 함수들 설정(모델 포함)\n",
    "- 비프음 함수\n",
    "- 음성 특징 추출 함수\n",
    "- 음성 특징 학습 함수(CNN)\n",
    "- 텍스트 임베딩 함수(KoBERT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817dc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#에러 발생 혹은 작업 완료시 beep로 알리기\n",
    "def beepError():\n",
    "    fr = 1000    # range : 37 ~ 32767\n",
    "    du = 2000     # 1000 ms ==1second\n",
    "    ws.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "\n",
    "def beepSuccess():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    ws.Beep(fr, du) # winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9de7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptual_sharpness(audio_path, sr=16000, n_fft=400, hop_length=160):\n",
    "    # 음원 파일 로드\n",
    "    y= audio_path\n",
    "    sr = sr\n",
    "\n",
    "    # STFT 수행\n",
    "    D = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
    "\n",
    "    # 주파수 대역별로 에너지 계산\n",
    "    energy = np.sum(D, axis=0)\n",
    "\n",
    "    # 고주파수 대역 성분 추출\n",
    "    high_freq_energy = energy[3000:8000]  # 예시로 3000Hz에서 6000Hz 사이의 주파수 대역을 고주파수 대역으로 설정\n",
    "\n",
    "    # Perceptual Sharpness 계산\n",
    "    sharpness = np.sum(np.log1p(high_freq_energy))\n",
    "\n",
    "    return sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97309fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(audio_path, csv_file):\n",
    "    feature_list = []\n",
    "#     file_array = np.array(csv_file['wav_id'])\n",
    "    file_array = np.array(csv_file) #테스트용\n",
    "\n",
    "    for i, file_name in tqdm(enumerate(file_array)):\n",
    "\n",
    "        audio, sr = librosa.load(os.path.join(audio_path, f'{file_name}.wav'), sr=16000)\n",
    "         ##Mel-spectrogram 구현\n",
    "        spectrogram = librosa.stft(audio, n_fft=400, hop_length= 160) \n",
    "        power_spectrogram = spectrogram**2\n",
    "        mel = librosa.feature.melspectrogram(S=power_spectrogram, sr=sr)\n",
    "        mel = librosa.power_to_db(np.abs(mel)**2)\n",
    "        #mfcc 구현\n",
    "        mfccs = librosa.feature.mfcc(S = mel, n_mfcc=100)\n",
    "        stft = np.abs(spectrogram)\n",
    "        chroma_stft = librosa.feature.chroma_stft(S=stft,hop_length=160)\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "        spectral_bandwidths = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "        zero_crossing_rates = librosa.feature.zero_crossing_rate(y=audio)\n",
    "        chroma_cens = librosa.feature.chroma_cens(C=spectrogram, sr=sr)\n",
    "        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        ps = perceptual_sharpness(audio)\n",
    "\n",
    "        try:\n",
    "            mfccs_mean = mfccs.mean(axis=1)\n",
    "            mfccs_var = mfccs.mean(axis=1)\n",
    "\n",
    "            for k in range(len(mfccs_mean)):\n",
    "                locals()[f'mfccs_mean_{k}'] = mfccs_mean[k]\n",
    "                locals()[f'mfccs_var_{k}'] = mfccs_var[k]\n",
    "                chroma_stft_mean = chroma_stft.mean()\n",
    "                chroma_stft_var = chroma_stft.var()\n",
    "                rms_mean = rms.mean()\n",
    "                rms_var = rms.var()\n",
    "                spectral_centroids_mean = spectral_centroids.mean()\n",
    "                spectral_centroids_var = spectral_centroids.var()\n",
    "                spectral_bandwidths_mean = spectral_bandwidths.mean()\n",
    "                spectral_bandwidths_var = spectral_bandwidths.var()\n",
    "                spectral_rolloff_mean = spectral_rolloff.mean()\n",
    "                spectral_rolloff_var = spectral_rolloff.var()\n",
    "                zero_crossing_rates_mean = zero_crossing_rates.mean()\n",
    "                zero_crossing_rates_var = zero_crossing_rates.var()\n",
    "                harmony_mean = chroma_cens.mean()\n",
    "                harmony_var = chroma_cens.var()\n",
    "                tempo_mean = tempo.mean()\n",
    "                tempo_var = tempo.var()\n",
    "                perceptual_sharpness_mean = ps.mean()\n",
    "                perceptual_sharpness_var = ps.var()\n",
    "        except Exception as e:\n",
    "            print(f'{i}번째 파일에서 문제 발생',e)\n",
    "            continue\n",
    "\n",
    "        #합치기\n",
    "        features = np.array([])\n",
    "        for j in range(len(mfccs_mean)):\n",
    "            features = np.hstack((features,locals()[f'mfccs_mean_{j}'],locals()[f'mfccs_var_{j}']))\n",
    "\n",
    "        features = np.hstack((features,chroma_stft_mean,chroma_stft_var,rms_mean,rms_var,spectral_centroids_mean\n",
    "                             ,spectral_centroids_var, spectral_bandwidths_mean, spectral_bandwidths_var,spectral_rolloff_mean\n",
    "                             , spectral_rolloff_var,zero_crossing_rates_mean, zero_crossing_rates_var, harmony_mean, harmony_var\n",
    "                             , tempo_mean,tempo_var,perceptual_sharpness_mean,perceptual_sharpness_var))\n",
    "        augmenter = naa.NoiseAug() #데이터 증강을 위해 노이즈된 특성 추가\n",
    "        augmented_features = np.squeeze(augmenter.augment(features))\n",
    "        features =np.hstack((features,augmented_features))\n",
    "\n",
    "        feature_list.append(features)\n",
    "    \n",
    "    \n",
    "    return feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adf9485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_2(audio_path, csv_file):\n",
    "    feature_list = []\n",
    "    file_array = np.array(csv_file['wav_id'])\n",
    "#     file_array = np.array(csv_file) #테스트용\n",
    "    augment = Compose([\n",
    "        AddGaussianNoise(p=0.5),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        Shift(p=0.5)\n",
    "        ])\n",
    "    for i, file_name in tqdm(enumerate(file_array)):\n",
    "\n",
    "        audio, sr = librosa.load(os.path.join(audio_path, f'{file_name}.wav'), sr=16000)\n",
    "        augmented_audio = augment(samples=audio, sample_rate=sr)\n",
    "         ##Mel-spectrogram 구현\n",
    "        spectrogram = librosa.stft(audio, n_fft=400, hop_length= 160) \n",
    "        power_spectrogram = spectrogram**2\n",
    "        mel = librosa.feature.melspectrogram(S=power_spectrogram, sr=sr)\n",
    "        mel = librosa.power_to_db(np.abs(mel)**2)\n",
    "        #mfcc 구현\n",
    "        mfccs = librosa.feature.mfcc(S = mel, n_mfcc=100)\n",
    "        stft = np.abs(spectrogram)\n",
    "        chroma_stft = librosa.feature.chroma_stft(S=stft,hop_length=160)\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "        spectral_bandwidths = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "        zero_crossing_rates = librosa.feature.zero_crossing_rate(y=audio)\n",
    "        chroma_cens = librosa.feature.chroma_cens(C=spectrogram, sr=sr)\n",
    "        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        ps = perceptual_sharpness(audio)\n",
    "\n",
    "        try:\n",
    "            mfccs_mean = mfccs.mean(axis=1)\n",
    "            mfccs_var = mfccs.mean(axis=1)\n",
    "\n",
    "            for k in range(len(mfccs_mean)):\n",
    "                locals()[f'mfccs_mean_{k}'] = mfccs_mean[k]\n",
    "                locals()[f'mfccs_var_{k}'] = mfccs_var[k]\n",
    "                chroma_stft_mean = chroma_stft.mean()\n",
    "                chroma_stft_var = chroma_stft.var()\n",
    "                rms_mean = rms.mean()\n",
    "                rms_var = rms.var()\n",
    "                spectral_centroids_mean = spectral_centroids.mean()\n",
    "                spectral_centroids_var = spectral_centroids.var()\n",
    "                spectral_bandwidths_mean = spectral_bandwidths.mean()\n",
    "                spectral_bandwidths_var = spectral_bandwidths.var()\n",
    "                spectral_rolloff_mean = spectral_rolloff.mean()\n",
    "                spectral_rolloff_var = spectral_rolloff.var()\n",
    "                zero_crossing_rates_mean = zero_crossing_rates.mean()\n",
    "                zero_crossing_rates_var = zero_crossing_rates.var()\n",
    "                harmony_mean = chroma_cens.mean()\n",
    "                harmony_var = chroma_cens.var()\n",
    "                tempo_mean = tempo.mean()\n",
    "                tempo_var = tempo.var()\n",
    "                perceptual_sharpness_mean = ps.mean()\n",
    "                perceptual_sharpness_var = ps.var()\n",
    "        except Exception as e:\n",
    "            print(f'{i}번째 파일에서 문제 발생',e)\n",
    "            continue\n",
    "\n",
    "        #합치기\n",
    "        features = np.array([])\n",
    "        for j in range(len(mfccs_mean)):\n",
    "            features = np.hstack((features,locals()[f'mfccs_mean_{j}'],locals()[f'mfccs_var_{j}']))\n",
    "\n",
    "        features = np.hstack((features,chroma_stft_mean,chroma_stft_var,rms_mean,rms_var,spectral_centroids_mean\n",
    "                             ,spectral_centroids_var, spectral_bandwidths_mean, spectral_bandwidths_var,spectral_rolloff_mean\n",
    "                             , spectral_rolloff_var,zero_crossing_rates_mean, zero_crossing_rates_var, harmony_mean, harmony_var\n",
    "                             , tempo_mean,tempo_var,perceptual_sharpness_mean,perceptual_sharpness_var))\n",
    "        # Audiomentations 증강 파이프라인 설정\n",
    "        spectrogram = librosa.stft(augmented_audio, n_fft=400, hop_length= 160) \n",
    "        power_spectrogram = spectrogram**2\n",
    "        mel = librosa.feature.melspectrogram(S=power_spectrogram, sr=sr)\n",
    "        mel = librosa.power_to_db(np.abs(mel)**2)\n",
    "        #mfcc 구현\n",
    "        mfccs = librosa.feature.mfcc(S = mel, n_mfcc=100)\n",
    "        stft = np.abs(spectrogram)\n",
    "        chroma_stft = librosa.feature.chroma_stft(S=stft,hop_length=160)\n",
    "        rms = librosa.feature.rms(y=augmented_audio)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=augmented_audio, sr=sr)\n",
    "        spectral_bandwidths = librosa.feature.spectral_bandwidth(y=augmented_audio, sr=sr)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=augmented_audio, sr=sr)\n",
    "        zero_crossing_rates = librosa.feature.zero_crossing_rate(y=augmented_audio)\n",
    "        chroma_cens = librosa.feature.chroma_cens(C=spectrogram, sr=sr)\n",
    "        tempo, _ = librosa.beat.beat_track(y=augmented_audio, sr=sr)\n",
    "        ps = perceptual_sharpness(augmented_audio)\n",
    "\n",
    "        try:\n",
    "            mfccs_mean = mfccs.mean(axis=1)\n",
    "            mfccs_var = mfccs.mean(axis=1)\n",
    "\n",
    "            for k in range(len(mfccs_mean)):\n",
    "                locals()[f'mfccs_mean_{k}'] = mfccs_mean[k]\n",
    "                locals()[f'mfccs_var_{k}'] = mfccs_var[k]\n",
    "                chroma_stft_mean = chroma_stft.mean()\n",
    "                chroma_stft_var = chroma_stft.var()\n",
    "                rms_mean = rms.mean()\n",
    "                rms_var = rms.var()\n",
    "                spectral_centroids_mean = spectral_centroids.mean()\n",
    "                spectral_centroids_var = spectral_centroids.var()\n",
    "                spectral_bandwidths_mean = spectral_bandwidths.mean()\n",
    "                spectral_bandwidths_var = spectral_bandwidths.var()\n",
    "                spectral_rolloff_mean = spectral_rolloff.mean()\n",
    "                spectral_rolloff_var = spectral_rolloff.var()\n",
    "                zero_crossing_rates_mean = zero_crossing_rates.mean()\n",
    "                zero_crossing_rates_var = zero_crossing_rates.var()\n",
    "                harmony_mean = chroma_cens.mean()\n",
    "                harmony_var = chroma_cens.var()\n",
    "                tempo_mean = tempo.mean()\n",
    "                tempo_var = tempo.var()\n",
    "                perceptual_sharpness_mean = ps.mean()\n",
    "                perceptual_sharpness_var = ps.var()\n",
    "        except Exception as e:\n",
    "            print(f'{i}번째 파일에서 문제 발생',e)\n",
    "            continue\n",
    "\n",
    "        #합치기\n",
    "        augmented_features = np.array([])\n",
    "        for j in range(len(mfccs_mean)):\n",
    "            augmented_features = np.hstack((augmented_features,locals()[f'mfccs_mean_{j}'],locals()[f'mfccs_var_{j}']))\n",
    "\n",
    "        augmented_features = np.hstack((augmented_features,chroma_stft_mean,chroma_stft_var,rms_mean,rms_var,spectral_centroids_mean\n",
    "                             ,spectral_centroids_var, spectral_bandwidths_mean, spectral_bandwidths_var,spectral_rolloff_mean\n",
    "                             , spectral_rolloff_var,zero_crossing_rates_mean, zero_crossing_rates_var, harmony_mean, harmony_var\n",
    "                             , tempo_mean,tempo_var,perceptual_sharpness_mean,perceptual_sharpness_var))\n",
    "        features =np.hstack((features,augmented_features))\n",
    "\n",
    "        feature_list.append(features)\n",
    "        # if i>0 and i%100 == 0:\n",
    "        #     print(f'{i}번째 파일 완료')\n",
    "        #     locals()[f'X_{int(i/100)}'] = np.array(feature_list).reshape(-1,len(feature_list[0]))\n",
    "    feature_array  = np.array(feature_list).reshape(-1,len(feature_list[0]))\n",
    "\n",
    "    return feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5c6d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5fbe364744697678c497c07f', '5fbe361844697678c497c07e']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au'5fbe364744697678c497c07f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = extract_feature(test_audio_path,test_list) #위 함수에서 test용으로 변경하고 실행해봄\n",
    "# features.shape\n",
    "features = extract_feature(train_audio_path,train_csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./features/train_features_6',features) # 6번째 train_features. 스케일링 안 된 것. 나중에 학습할 때 스케일링 fit 해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = extract_feature(valid_audio_path,valid_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea75a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./features/valid_features_6',val_features) # valid features는 사실 두 번째지만 train_features랑 번호를 맞추기 위해서. 이것도 나중에 스케일러로 트랜스폼해 줘야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5285a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_feature_2(train_audio_path,train_csv) \n",
    "\n",
    "#3395번째 파일에서 문제 발생...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb308695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-661.94946289+0.j -661.94946289+0.j    5.81620216+0.j    5.81620216+0.j\n",
      "    5.66127253+0.j]\n",
      "[-661.94946289+0.j -661.94946289+0.j    5.81620216+0.j    5.81620216+0.j\n",
      "    5.66127253+0.j]\n"
     ]
    }
   ],
   "source": [
    "print(feature_array[0][0:5])\n",
    "print(val_features[3395][0:5])\n",
    "\n",
    "# val_features= np.insert(val_features,3395,feature_array,axis=0)\n",
    "# np.save('./features/train_features_7',val_features) # 해당 파일 특징 개별 추출해서 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dda0f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./features/train_features_7',features) # 스케일링 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "106bf1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29319, 436)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11138it [43:59,  5.37it/s]"
     ]
    }
   ],
   "source": [
    "val_features = extract_feature_2(valid_audio_path,valid_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69dffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./features/valid_features_7',val_features) #스케일링 안 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c56214df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29319, 436)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(data):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(data.shape[1],data.shape[2])))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adamW' , loss = 'categorical_crossentropy' , metrics = ['accuracy',recall,precision]) #metrics 추가\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f941d4",
   "metadata": {},
   "source": [
    "### 결과\n",
    "- 이 파일과는 별도로 Colab에서 KoBERT를 실행해 보려고 했으나 자꾸 import 관련해서 문제가 생김\n",
    "- 작동하는 데 문제가 없고 KoBERT보다 감정분석에서 뛰어난 성능을 보이는 KoELECTRA로 대체하기로 함(9차 시도)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
